{"id": "data/docs/augmentation.md#c0", "source": "docs", "text": "---\ntitle: \"Data Augmentation (v2.1)\"\nlast_updated: \"2025-07-03\"\nowner: \"AstraML Docs\"\n---\n# Overview\nDefaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n## Request Schema\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nDefaults can be overridden in the request body or via project-level policies. Use explicit versioning to avoid unexpected behavior during rolling upgrades. The examples below illustrate recommended values for common workloads. The API guarantees eventual consistency for metrics and near real-time visibility for logs. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. This section describes the behavior under different failure modes and how clients should react. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n## Troubleshooting\nDefaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Use explicit versioning to avoid unexpected behavior during rolling upgrades. The examples below illustrate recommended values for common workloads. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "augmentation.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/autoscaling.md#c0", "source": "docs", "text": "---\ntitle: \"Autoscaling (v2.1)\"\nlast_updated: \"2025-05-14\"\nowner: \"Core Platform\"\n---\n# Overview\nThis document describes the Autoscaling module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-535\",\n  \"dataset\": \"s3://bucket/dataset-7\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "autoscaling.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/billing.md#c0", "source": "docs", "text": "---\ntitle: \"Billing & Limits (v2.1)\"\nlast_updated: \"2025-06-26\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. The examples below illustrate recommended values for common workloads. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Defaults can be overridden in the request body or via project-level policies.\n\n## Request Schema\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The examples below illustrate recommended values for common workloads. Defaults can be overridden in the request body or via project-level policies. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. This section describes the behavior under different failure modes and how clients should react. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nThis section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n## Troubleshooting\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. This section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs. The examples below illustrate recommended values for common workloads. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "billing.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/billing_and_limits.md#c0", "source": "docs", "text": "---\ntitle: \"Billing & Limits (v2.1)\"\nlast_updated: \"2025-07-26\"\nowner: \"ML Systems\"\n---\n# Overview\nThis document describes the Billing & Limits module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-807\",\n  \"dataset\": \"s3://bucket/dataset-8\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "billing_and_limits.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/checkpoints.md#c0", "source": "docs", "text": "---\ntitle: \"Checkpoints & Recovery (v2.1)\"\nlast_updated: \"2025-06-22\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. Defaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n## Request Schema\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. We recommend using idempotency keys for retriable operations to prevent duplicate work. The examples below illustrate recommended values for common workloads.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Use explicit versioning to avoid unexpected behavior during rolling upgrades. We recommend using idempotency keys for retriable operations to prevent duplicate work. This section describes the behavior under different failure modes and how clients should react.\n\n## Troubleshooting\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "checkpoints.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/checkpoints_and_recovery.md#c0", "source": "docs", "text": "---\ntitle: \"Checkpoints & Recovery (v2.1)\"\nlast_updated: \"2025-07-10\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Checkpoints & Recovery module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-168\",\n  \"dataset\": \"s3://bucket/dataset-9\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "checkpoints_and_recovery.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/compute_quotas.md#c0", "source": "docs", "text": "---\ntitle: \"Compute Quotas (v2.1)\"\nlast_updated: \"2025-05-26\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Compute Quotas module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-207\",\n  \"dataset\": \"s3://bucket/dataset-5\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "compute_quotas.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/data_augmentation.md#c0", "source": "docs", "text": "---\ntitle: \"Data Augmentation (v2.1)\"\nlast_updated: \"2025-05-10\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Data Augmentation module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-517\",\n  \"dataset\": \"s3://bucket/dataset-1\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "data_augmentation.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/data_formats.md#c0", "source": "docs", "text": "---\ntitle: \"Datasets & Data Formats (v2.1)\"\nlast_updated: \"2025-06-21\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. The examples below illustrate recommended values for common workloads. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n## Request Schema\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. The examples below illustrate recommended values for common workloads. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Defaults can be overridden in the request body or via project-level policies.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The examples below illustrate recommended values for common workloads. This section describes the behavior under different failure modes and how clients should react. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Defaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n## Troubleshooting\nThe examples below illustrate recommended values for common workloads. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "data_formats.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/datasets.md#c0", "source": "docs", "text": "---\ntitle: \"Datasets (v2.1)\"\nlast_updated: \"2025-07-13\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Datasets module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-699\",\n  \"dataset\": \"s3://bucket/dataset-3\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "datasets.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/deployment_api.md#c0", "source": "docs", "text": "---\ntitle: \"Deployment API (v2.1)\"\nlast_updated: \"2025-06-12\"\nowner: \"ML Systems\"\n---\n# Overview\nThis document describes the Deployment API module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-492\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "deployment_api.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/distributed.md#c0", "source": "docs", "text": "---\ntitle: \"Distributed Training (v2.1)\"\nlast_updated: \"2025-07-03\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. The examples below illustrate recommended values for common workloads. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures.\n\n## Request Schema\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. This section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs. The examples below illustrate recommended values for common workloads.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. Defaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads.\n\n## Troubleshooting\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "distributed.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/distributed_training.md#c0", "source": "docs", "text": "---\ntitle: \"Distributed Training (v2.1)\"\nlast_updated: \"2025-07-19\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Distributed Training module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-691\",\n  \"dataset\": \"s3://bucket/dataset-1\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "distributed_training.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/hyperparams.md#c0", "source": "docs", "text": "---\ntitle: \"Hyperparameters (v2.1)\"\nlast_updated: \"2025-06-24\"\nowner: \"AstraML Docs\"\n---\n# Overview\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Defaults can be overridden in the request body or via project-level policies. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The examples below illustrate recommended values for common workloads.\n\n## Request Schema\nDefaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. The API guarantees eventual consistency for metrics and near real-time visibility for logs. This section describes the behavior under different failure modes and how clients should react.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nDefaults can be overridden in the request body or via project-level policies. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n## Troubleshooting\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. This section describes the behavior under different failure modes and how clients should react. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Defaults can be overridden in the request body or via project-level policies. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "hyperparams.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/inference_api.md#c0", "source": "docs", "text": "---\ntitle: \"Inference API (v2.1)\"\nlast_updated: \"2025-06-09\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Inference API module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-500\",\n  \"dataset\": \"s3://bucket/dataset-4\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "inference_api.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/job_schedules.md#c0", "source": "docs", "text": "---\ntitle: \"Job Schedules (v2.1)\"\nlast_updated: \"2025-07-17\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Job Schedules module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-371\",\n  \"dataset\": \"s3://bucket/dataset-4\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "job_schedules.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/model_registry.md#c0", "source": "docs", "text": "---\ntitle: \"Model Registry (v2.1)\"\nlast_updated: \"2025-07-24\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Model Registry module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-984\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "model_registry.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/monitoring.md#c0", "source": "docs", "text": "---\ntitle: \"Monitoring & Metrics (v2.1)\"\nlast_updated: \"2025-07-10\"\nowner: \"AstraML Docs\"\n---\n# Overview\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Defaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n## Request Schema\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies. The examples below illustrate recommended values for common workloads. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. We recommend using idempotency keys for retriable operations to prevent duplicate work. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies. The examples below illustrate recommended values for common workloads. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures.\n\n## Troubleshooting\nThe examples below illustrate recommended values for common workloads. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. We recommend using idempotency keys for retriable operations to prevent duplicate work. The API guarantees eventual consistency for metrics and near real-time visibility for logs. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "monitoring.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/monitoring_and_metrics.md#c0", "source": "docs", "text": "---\ntitle: \"Monitoring & Metrics (v2.1)\"\nlast_updated: \"2025-05-09\"\nowner: \"Core Platform\"\n---\n# Overview\nThis document describes the Monitoring & Metrics module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-617\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "monitoring_and_metrics.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/permissions.md#c0", "source": "docs", "text": "---\ntitle: \"Permissions & Roles (v2.1)\"\nlast_updated: \"2025-07-06\"\nowner: \"AstraML Docs\"\n---\n# Overview\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n## Request Schema\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. We recommend using idempotency keys for retriable operations to prevent duplicate work. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. We recommend using idempotency keys for retriable operations to prevent duplicate work. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n## Troubleshooting\nThe examples below illustrate recommended values for common workloads. Defaults can be overridden in the request body or via project-level policies. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "permissions.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/permissions_and_roles.md#c0", "source": "docs", "text": "---\ntitle: \"Permissions & Roles (v2.1)\"\nlast_updated: \"2025-06-01\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Permissions & Roles module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-275\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "permissions_and_roles.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/quotas.md#c0", "source": "docs", "text": "---\ntitle: \"Compute Quotas (v2.1)\"\nlast_updated: \"2025-07-02\"\nowner: \"AstraML Docs\"\n---\n# Overview\nThe examples below illustrate recommended values for common workloads. The API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. This section describes the behavior under different failure modes and how clients should react. We recommend using idempotency keys for retriable operations to prevent duplicate work. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n## Request Schema\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. This section describes the behavior under different failure modes and how clients should react. The examples below illustrate recommended values for common workloads. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. We recommend using idempotency keys for retriable operations to prevent duplicate work. The examples below illustrate recommended values for common workloads. This section describes the behavior under different failure modes and how clients should react. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n## Troubleshooting\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "quotas.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/retries.md#c0", "source": "docs", "text": "---\ntitle: \"Retries & Timeouts (v2.1)\"\nlast_updated: \"2025-07-01\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. This section describes the behavior under different failure modes and how clients should react.\n\n## Request Schema\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThis section describes the behavior under different failure modes and how clients should react. The examples below illustrate recommended values for common workloads. Defaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n## Troubleshooting\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "retries.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/retries_and_timeouts.md#c0", "source": "docs", "text": "---\ntitle: \"Retries & Timeouts (v2.1)\"\nlast_updated: \"2025-06-21\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Retries & Timeouts module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-513\",\n  \"dataset\": \"s3://bucket/dataset-5\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "retries_and_timeouts.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/schedules.md#c0", "source": "docs", "text": "---\ntitle: \"Job Schedules (v2.1)\"\nlast_updated: \"2025-06-21\"\nowner: \"AstraML Docs\"\n---\n# Overview\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. The examples below illustrate recommended values for common workloads. Defaults can be overridden in the request body or via project-level policies. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n## Request Schema\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. The API guarantees eventual consistency for metrics and near real-time visibility for logs. This section describes the behavior under different failure modes and how clients should react. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. The API guarantees eventual consistency for metrics and near real-time visibility for logs. This section describes the behavior under different failure modes and how clients should react. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. The API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Defaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n## Troubleshooting\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs. The examples below illustrate recommended values for common workloads. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "schedules.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/security.md#c0", "source": "docs", "text": "---\ntitle: \"Security & Secrets (v2.1)\"\nlast_updated: \"2025-06-21\"\nowner: \"AstraML Docs\"\n---\n# Overview\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n## Request Schema\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. The examples below illustrate recommended values for common workloads. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. This section describes the behavior under different failure modes and how clients should react. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThis section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs. The examples below illustrate recommended values for common workloads. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. The examples below illustrate recommended values for common workloads. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n## Troubleshooting\nDefaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Metrics are aggregated in 30-second windows by default and support downsampling for long retention.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "security.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/security_and_secrets.md#c0", "source": "docs", "text": "---\ntitle: \"Security & Secrets (v2.1)\"\nlast_updated: \"2025-07-16\"\nowner: \"ML Systems\"\n---\n# Overview\nThis document describes the Security & Secrets module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-221\",\n  \"dataset\": \"s3://bucket/dataset-8\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "security_and_secrets.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/storage.md#c0", "source": "docs", "text": "---\ntitle: \"Storage & Artifacts (v2.1)\"\nlast_updated: \"2025-07-08\"\nowner: \"AstraML Docs\"\n---\n# Overview\nAll endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Use explicit versioning to avoid unexpected behavior during rolling upgrades. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. Defaults can be overridden in the request body or via project-level policies.\n\n## Request Schema\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Defaults can be overridden in the request body or via project-level policies. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThe examples below illustrate recommended values for common workloads. The API guarantees eventual consistency for metrics and near real-time visibility for logs. We recommend using idempotency keys for retriable operations to prevent duplicate work. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. We recommend using idempotency keys for retriable operations to prevent duplicate work. Defaults can be overridden in the request body or via project-level policies.\n\n## Troubleshooting\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. Use explicit versioning to avoid unexpected behavior during rolling upgrades. Defaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "storage.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/storage_and_artifacts.md#c0", "source": "docs", "text": "---\ntitle: \"Storage & Artifacts (v2.1)\"\nlast_updated: \"2025-07-24\"\nowner: \"Product Engineering\"\n---\n# Overview\nThis document describes the Storage & Artifacts module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-118\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "storage_and_artifacts.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/training_api.md#c0", "source": "docs", "text": "---\ntitle: \"Training API (v2.1)\"\nlast_updated: \"2025-07-19\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Training API module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-646\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "training_api.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/troubleshooting.md#c0", "source": "docs", "text": "---\ntitle: \"Troubleshooting Guide (v2.1)\"\nlast_updated: \"2025-06-27\"\nowner: \"AstraML Docs\"\n---\n# Overview\nSecurity-sensitive fields should be passed via project-scoped secrets rather than inline literals. We recommend using idempotency keys for retriable operations to prevent duplicate work. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n## Request Schema\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. This section describes the behavior under different failure modes and how clients should react. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nUse explicit versioning to avoid unexpected behavior during rolling upgrades. We recommend using idempotency keys for retriable operations to prevent duplicate work. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. The API guarantees eventual consistency for metrics and near real-time visibility for logs. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nWe recommend using idempotency keys for retriable operations to prevent duplicate work. Defaults can be overridden in the request body or via project-level policies. This section describes the behavior under different failure modes and how clients should react. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The API guarantees eventual consistency for metrics and near real-time visibility for logs.\n\n## Troubleshooting\nThe API guarantees eventual consistency for metrics and near real-time visibility for logs. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. We recommend using idempotency keys for retriable operations to prevent duplicate work. This section describes the behavior under different failure modes and how clients should react. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "troubleshooting.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/troubleshooting_guide.md#c0", "source": "docs", "text": "---\ntitle: \"Troubleshooting Guide (v2.1)\"\nlast_updated: \"2025-05-02\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Troubleshooting Guide module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-914\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "troubleshooting_guide.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/tuning.md#c0", "source": "docs", "text": "---\ntitle: \"Hyperparameter Tuning Service (v2.1)\"\nlast_updated: \"2025-06-22\"\nowner: \"AstraML Docs\"\n---\n# Overview\nDefaults can be overridden in the request body or via project-level policies. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. We recommend using idempotency keys for retriable operations to prevent duplicate work. Use explicit versioning to avoid unexpected behavior during rolling upgrades. This section describes the behavior under different failure modes and how clients should react. The examples below illustrate recommended values for common workloads.\n\n## Request Schema\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. The API guarantees eventual consistency for metrics and near real-time visibility for logs. The examples below illustrate recommended values for common workloads. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. This section describes the behavior under different failure modes and how clients should react.\n\n```json\n{\n  \"project_id\": \"p-demo\",\n  \"dataset\": \"s3://bucket/dataset\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5}\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n## Usage Examples\nThis section describes the behavior under different failure modes and how clients should react. The API guarantees eventual consistency for metrics and near real-time visibility for logs. Use explicit versioning to avoid unexpected behavior during rolling upgrades. When migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. The examples below illustrate recommended values for common workloads.\n\n```bash\nastraml submit --project p-demo --model bert-base --gpus 1           --dataset s3://bucket/dataset --batch-size 32 --epochs 5 --lr 3e-5\n```\n\n## Defaults & Notes\n- batch_size: 32\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- gradient_accumulation_steps: 1\n\nMetrics are aggregated in 30-second windows by default and support downsampling for long retention. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. This section describes the behavior under different failure modes and how clients should react. We recommend using idempotency keys for retriable operations to prevent duplicate work. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n## Troubleshooting\nWhen migrating from v1.x, verify scheduler, patience, and batch size to align with v2.1 defaults. Metrics are aggregated in 30-second windows by default and support downsampling for long retention. This section describes the behavior under different failure modes and how clients should react. Security-sensitive fields should be passed via project-scoped secrets rather than inline literals. All endpoints follow standard HTTP semantics; 4xx indicates client issues, 5xx indicates server-side failures. Use explicit versioning to avoid unexpected behavior during rolling upgrades.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources:\n  gpus: 1\nhyperparams:\n  lr_scheduler: cosine\n  gradient_accumulation_steps: 1\n```", "meta": {"doc_title": "tuning.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/tuning_service.md#c0", "source": "docs", "text": "---\ntitle: \"Tuning Service (v2.1)\"\nlast_updated: \"2025-07-26\"\nowner: \"Infra Team\"\n---\n# Overview\nThis document describes the Tuning Service module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-117\",\n  \"dataset\": \"s3://bucket/dataset-4\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "tuning_service.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/docs/warmup_and_schedulers.md#c0", "source": "docs", "text": "---\ntitle: \"Warmup & Schedulers (v2.1)\"\nlast_updated: \"2025-05-26\"\nowner: \"AstraML Docs\"\n---\n# Overview\nThis document describes the Warmup & Schedulers module in AstraML v2.1. It outlines supported fields, defaults, migration notes from v1.x, and example usage. The intent is normative and versioned; readers should treat this as the authoritative specification.\n\n## Request Schema\n\n```json\n{\n  \"project_id\": \"proj-563\",\n  \"dataset\": \"s3://bucket/dataset-6\",\n  \"model\": \"bert-base\",\n  \"hyperparams\": {\n    \"batch_size\": 32,\n    \"lr\": 3e-5,\n    \"epochs\": 5,\n    \"early_stopping\": {\"patience\": 5},\n    \"lr_scheduler\": \"cosine\",\n    \"gradient_accumulation_steps\": 1\n  },\n  \"resources\": {\"gpus\": 1}\n}\n```\n\n\n## Usage Examples\n\n```bash\n# submit a standard job\nastraml submit --project demo --model bert-base --gpus 1 \\      --dataset s3://bucket/ds --batch-size 32 --epochs 5 --lr 3e-5\n\n# fetch metrics\nastraml metrics --job-id 12345 --window 30s\n```\n\n\n## Defaults & Notes\n- batch_size: 32 (v2.1 default)\n- lr: 3e-5\n- epochs: 5\n- early_stopping.patience: 5\n- lr_scheduler: cosine\n- concurrency: 2 (legacy tenants may observe 1)\n- artifact_retention_days: 30\n- storage_quota_tb: 5\nNotes: These defaults may evolve; consult last_updated for changes.\n\nImplementation details emphasize determinism and backward compatibility where feasible. Where behavior changed from v1.x, the change is documented with explicit rationale. Examples are intentionally minimal to reduce ambiguity and copy-paste errors. Security-sensitive fields should be supplied via secret references, not inline strings.\n\n## Troubleshooting\nIf jobs queue for longer than expected, confirm available quota and see autoscaling cooldown. For 429s on inference endpoints, reduce burst RPM or apply token budgets. If registry automation fails, verify permissions and roll back to a known-good snapshot.\n\n```yaml\nschedule:\n  cron: \"0 * * * *\"\nresources: { gpus: 1 }\n```", "meta": {"doc_title": "warmup_and_schedulers.md", "section_path": [], "version": "v2.1", "content_type": "prose"}}
{"id": "data/forums/t001#qa", "source": "forums", "text": "Q: What is the default batch_size in AstraML v2.1? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t001", "title": "batch_size default", "accepted": true, "upvotes": 40, "author": "staff_mina", "timestamp": "2025-07-12"}}
{"id": "data/forums/t001#a0011", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t001", "title": "batch_size default", "accepted": false, "upvotes": 16, "author": "dev_alex", "timestamp": "2025-06-24"}}
{"id": "data/forums/t001#a0012", "source": "forums", "text": "Answer: Concurrency=1 can happen on legacy clusters; file a ticket to migrate capacity class.", "meta": {"thread_id": "t001", "title": "batch_size default", "accepted": false, "upvotes": 18, "author": "ml_jane", "timestamp": "2025-06-05"}}
{"id": "data/forums/t002#qa", "source": "forums", "text": "Q: Is patience still 3 or changed in v2.1? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t002", "title": "early stopping patience", "accepted": true, "upvotes": 29, "author": "platform_ops", "timestamp": "2025-06-07"}}
{"id": "data/forums/t002#a0021", "source": "forums", "text": "Answer: On some CV tasks we saw batch_size=64 perform better—measure memory headroom first.", "meta": {"thread_id": "t002", "title": "early stopping patience", "accepted": false, "upvotes": 6, "author": "community_karl", "timestamp": "2025-06-07"}}
{"id": "data/forums/t003#qa", "source": "forums", "text": "Q: Does v2.1 use cosine or step LR scheduler by default? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t003", "title": "scheduler type", "accepted": true, "upvotes": 31, "author": "staff_mina", "timestamp": "2025-07-10"}}
{"id": "data/forums/t003#a0031", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t003", "title": "scheduler type", "accepted": false, "upvotes": 16, "author": "dev_alex", "timestamp": "2025-07-20"}}
{"id": "data/forums/t004#qa", "source": "forums", "text": "Q: Why do some tenants see concurrency=1? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t004", "title": "concurrency slots", "accepted": true, "upvotes": 17, "author": "staff_raj", "timestamp": "2025-06-02"}}
{"id": "data/forums/t004#a0041", "source": "forums", "text": "Answer: Concurrency=1 can happen on legacy clusters; file a ticket to migrate capacity class.", "meta": {"thread_id": "t004", "title": "concurrency slots", "accepted": false, "upvotes": 14, "author": "ops_li", "timestamp": "2025-07-04"}}
{"id": "data/forums/t005#qa", "source": "forums", "text": "Q: How long are artifacts kept by default? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t005", "title": "artifact retention", "accepted": true, "upvotes": 6, "author": "staff_mina", "timestamp": "2025-07-05"}}
{"id": "data/forums/t005#a0051", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t005", "title": "artifact retention", "accepted": false, "upvotes": 3, "author": "ml_jane", "timestamp": "2025-07-09"}}
{"id": "data/forums/t006#qa", "source": "forums", "text": "Q: What is the default storage quota per project? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t006", "title": "storage limits", "accepted": true, "upvotes": 7, "author": "staff_mina", "timestamp": "2025-07-21"}}
{"id": "data/forums/t006#a0061", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t006", "title": "storage limits", "accepted": false, "upvotes": 11, "author": "dev_alex", "timestamp": "2025-07-08"}}
{"id": "data/forums/t007#qa", "source": "forums", "text": "Q: Is 10s metrics supported by default? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t007", "title": "metrics granularity", "accepted": true, "upvotes": 34, "author": "docs_team", "timestamp": "2025-06-29"}}
{"id": "data/forums/t007#a0071", "source": "forums", "text": "Answer: We keep artifacts for 60 days in regulated projects; default remains 30.", "meta": {"thread_id": "t007", "title": "metrics granularity", "accepted": false, "upvotes": 16, "author": "community_karl", "timestamp": "2025-07-05"}}
{"id": "data/forums/t008#qa", "source": "forums", "text": "Q: How to handle 429 on inference endpoints? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t008", "title": "rate limits", "accepted": true, "upvotes": 34, "author": "platform_ops", "timestamp": "2025-07-15"}}
{"id": "data/forums/t008#a0081", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t008", "title": "rate limits", "accepted": false, "upvotes": 13, "author": "dev_alex", "timestamp": "2025-07-19"}}
{"id": "data/forums/t009#qa", "source": "forums", "text": "Q: Can models be auto-registered after training? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t009", "title": "registry automation", "accepted": true, "upvotes": 26, "author": "staff_raj", "timestamp": "2025-06-23"}}
{"id": "data/forums/t009#a0091", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t009", "title": "registry automation", "accepted": false, "upvotes": 16, "author": "ops_li", "timestamp": "2025-06-11"}}
{"id": "data/forums/t010#qa", "source": "forums", "text": "Q: Is there a dataset size hard limit? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t010", "title": "dataset size", "accepted": true, "upvotes": 22, "author": "docs_team", "timestamp": "2025-06-19"}}
{"id": "data/forums/t010#a0101", "source": "forums", "text": "Answer: On some CV tasks we saw batch_size=64 perform better—measure memory headroom first.", "meta": {"thread_id": "t010", "title": "dataset size", "accepted": false, "upvotes": 17, "author": "ml_jane", "timestamp": "2025-07-13"}}
{"id": "data/forums/t010#a0102", "source": "forums", "text": "Answer: We keep artifacts for 60 days in regulated projects; default remains 30.", "meta": {"thread_id": "t010", "title": "dataset size", "accepted": false, "upvotes": 17, "author": "ops_li", "timestamp": "2025-07-07"}}
{"id": "data/forums/t011#qa", "source": "forums", "text": "Q: Do we need warmup steps for short runs? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t011", "title": "warmup", "accepted": true, "upvotes": 14, "author": "staff_mina", "timestamp": "2025-06-23"}}
{"id": "data/forums/t011#a0111", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t011", "title": "warmup", "accepted": false, "upvotes": 12, "author": "ops_li", "timestamp": "2025-07-03"}}
{"id": "data/forums/t012#qa", "source": "forums", "text": "Q: How to set gradient_accumulation_steps? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t012", "title": "accumulation", "accepted": true, "upvotes": 20, "author": "docs_team", "timestamp": "2025-07-08"}}
{"id": "data/forums/t012#a0121", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t012", "title": "accumulation", "accepted": false, "upvotes": 18, "author": "community_karl", "timestamp": "2025-07-14"}}
{"id": "data/forums/t013#qa", "source": "forums", "text": "Q: Why do jobs queue even when GPUs look idle? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t013", "title": "autoscaling cooldown", "accepted": true, "upvotes": 7, "author": "staff_raj", "timestamp": "2025-06-14"}}
{"id": "data/forums/t013#a0131", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t013", "title": "autoscaling cooldown", "accepted": false, "upvotes": 4, "author": "community_karl", "timestamp": "2025-07-25"}}
{"id": "data/forums/t014#qa", "source": "forums", "text": "Q: Recommended timeouts for long-running jobs? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t014", "title": "timeouts", "accepted": true, "upvotes": 41, "author": "staff_raj", "timestamp": "2025-06-17"}}
{"id": "data/forums/t014#a0141", "source": "forums", "text": "Answer: On some CV tasks we saw batch_size=64 perform better—measure memory headroom first.", "meta": {"thread_id": "t014", "title": "timeouts", "accepted": false, "upvotes": 18, "author": "community_karl", "timestamp": "2025-06-13"}}
{"id": "data/forums/t015#qa", "source": "forums", "text": "Q: How many retries are safe without wasting compute? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t015", "title": "retries", "accepted": true, "upvotes": 14, "author": "staff_raj", "timestamp": "2025-07-25"}}
{"id": "data/forums/t015#a0151", "source": "forums", "text": "Answer: We keep artifacts for 60 days in regulated projects; default remains 30.", "meta": {"thread_id": "t015", "title": "retries", "accepted": false, "upvotes": 8, "author": "ml_jane", "timestamp": "2025-07-17"}}
{"id": "data/forums/t016#qa", "source": "forums", "text": "Q: Best practice for canary rollout percentage? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t016", "title": "canary", "accepted": true, "upvotes": 25, "author": "docs_team", "timestamp": "2025-06-10"}}
{"id": "data/forums/t016#a0161", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t016", "title": "canary", "accepted": false, "upvotes": 19, "author": "community_karl", "timestamp": "2025-07-21"}}
{"id": "data/forums/t016#a0162", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t016", "title": "canary", "accepted": false, "upvotes": 2, "author": "ml_jane", "timestamp": "2025-06-16"}}
{"id": "data/forums/t017#qa", "source": "forums", "text": "Q: How to recover from spot preemption quickly? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t017", "title": "preemption", "accepted": true, "upvotes": 31, "author": "docs_team", "timestamp": "2025-07-22"}}
{"id": "data/forums/t017#a0171", "source": "forums", "text": "Answer: On some CV tasks we saw batch_size=64 perform better—measure memory headroom first.", "meta": {"thread_id": "t017", "title": "preemption", "accepted": false, "upvotes": 11, "author": "ops_li", "timestamp": "2025-06-24"}}
{"id": "data/forums/t018#qa", "source": "forums", "text": "Q: Why am I billed when GPUs look idle? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t018", "title": "billing idle", "accepted": true, "upvotes": 38, "author": "platform_ops", "timestamp": "2025-06-21"}}
{"id": "data/forums/t018#a0181", "source": "forums", "text": "Answer: On some CV tasks we saw batch_size=64 perform better—measure memory headroom first.", "meta": {"thread_id": "t018", "title": "billing idle", "accepted": false, "upvotes": 4, "author": "ops_li", "timestamp": "2025-07-17"}}
{"id": "data/forums/t018#a0182", "source": "forums", "text": "Answer: 10s metrics are optional and cost more; default window is 30s.", "meta": {"thread_id": "t018", "title": "billing idle", "accepted": false, "upvotes": 14, "author": "community_karl", "timestamp": "2025-07-10"}}
{"id": "data/forums/t019#qa", "source": "forums", "text": "Q: How to pass secrets without hardcoding? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t019", "title": "security secrets", "accepted": true, "upvotes": 31, "author": "docs_team", "timestamp": "2025-06-22"}}
{"id": "data/forums/t019#a0191", "source": "forums", "text": "Answer: Old tenants still on v1.x likely have patience=3 and step scheduler; migrate to v2.1.", "meta": {"thread_id": "t019", "title": "security secrets", "accepted": false, "upvotes": 19, "author": "ml_jane", "timestamp": "2025-06-17"}}
{"id": "data/forums/t020#qa", "source": "forums", "text": "Q: Who can approve registry changes? A: Docs say v2.1 default is batch_size=32; patience=5; lr_scheduler=cosine; concurrency=2 (legacy may see 1); artifacts=30 days; storage=5TB.", "meta": {"thread_id": "t020", "title": "permissions", "accepted": true, "upvotes": 12, "author": "docs_team", "timestamp": "2025-06-15"}}
{"id": "data/forums/t020#a0201", "source": "forums", "text": "Answer: Concurrency=1 can happen on legacy clusters; file a ticket to migrate capacity class.", "meta": {"thread_id": "t020", "title": "permissions", "accepted": false, "upvotes": 20, "author": "ml_jane", "timestamp": "2025-07-15"}}
{"id": "data/blogs/post_01.md#c0", "source": "blogs", "text": "---\nauthor: \"Research\"\npublished_date: \"2025-04-10\"\ntitle: \"Throughput vs Cost Benchmarks\"\n---\n# Throughput vs Cost Benchmarks\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-1 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_01.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_02.md#c0", "source": "blogs", "text": "---\nauthor: \"Platform\"\npublished_date: \"2025-06-12\"\ntitle: \"When batch_size=64 Wins (Sometimes)\"\n---\n# When batch_size=64 Wins (Sometimes)\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-2 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_02.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_03.md#c0", "source": "blogs", "text": "---\nauthor: \"Security\"\npublished_date: \"2024-12-02\"\ntitle: \"Patience Isn’t Free: Early Stopping in Practice\"\n---\n# Patience Isn’t Free: Early Stopping in Practice\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-3 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_03.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_04.md#c0", "source": "blogs", "text": "---\nauthor: \"Dev Team\"\npublished_date: \"2025-05-12\"\ntitle: \"Cosine vs Step: Field Notes\"\n---\n# Cosine vs Step: Field Notes\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-4 --batch-size 64 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_04.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_05.md#c0", "source": "blogs", "text": "---\nauthor: \"Karl Chen\"\npublished_date: \"2025-05-26\"\ntitle: \"Concurrency Oddities on Legacy Tenants\"\n---\n# Concurrency Oddities on Legacy Tenants\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-5 --batch-size 64 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_05.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_06.md#c0", "source": "blogs", "text": "---\nauthor: \"Community\"\npublished_date: \"2025-06-13\"\ntitle: \"Why Some Teams Keep 60-Day Artifacts\"\n---\n# Why Some Teams Keep 60-Day Artifacts\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-6 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_06.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_07.md#c0", "source": "blogs", "text": "---\nauthor: \"Community\"\npublished_date: \"2024-10-05\"\ntitle: \"Warmup & Accumulation Interactions\"\n---\n# Warmup & Accumulation Interactions\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-7 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_07.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_08.md#c0", "source": "blogs", "text": "---\nauthor: \"Karl Chen\"\npublished_date: \"2024-11-27\"\ntitle: \"Granularity of Metrics: 10s vs 30s\"\n---\n# Granularity of Metrics: 10s vs 30s\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-8 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_08.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_09.md#c0", "source": "blogs", "text": "---\nauthor: \"SRE\"\npublished_date: \"2024-12-08\"\ntitle: \"Retries, Timeouts, and Wasted Compute\"\n---\n# Retries, Timeouts, and Wasted Compute\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-9 --batch-size 64 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_09.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_10.md#c0", "source": "blogs", "text": "---\nauthor: \"Ops\"\npublished_date: \"2024-09-28\"\ntitle: \"Scaling Queues and Cooldowns\"\n---\n# Scaling Queues and Cooldowns\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-10 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_10.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_11.md#c0", "source": "blogs", "text": "---\nauthor: \"ML Eng\"\npublished_date: \"2025-02-26\"\ntitle: \"Auto-Register Pitfalls in the Registry\"\n---\n# Auto-Register Pitfalls in the Registry\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-11 --batch-size 24 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_11.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_12.md#c0", "source": "blogs", "text": "---\nauthor: \"Platform\"\npublished_date: \"2025-01-26\"\ntitle: \"Secrets Hygiene in Real Projects\"\n---\n# Secrets Hygiene in Real Projects\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-12 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_12.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_13.md#c0", "source": "blogs", "text": "---\nauthor: \"SRE\"\npublished_date: \"2025-04-25\"\ntitle: \"GCS vs S3 Mounts: Latency Notes\"\n---\n# GCS vs S3 Mounts: Latency Notes\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-13 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_13.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_14.md#c0", "source": "blogs", "text": "---\nauthor: \"Platform\"\npublished_date: \"2024-10-06\"\ntitle: \"Inference Rate Limits Tuning\"\n---\n# Inference Rate Limits Tuning\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-14 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_14.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_15.md#c0", "source": "blogs", "text": "---\nauthor: \"SRE\"\npublished_date: \"2025-01-13\"\ntitle: \"Canary Deployments: Tales from Rollbacks\"\n---\n# Canary Deployments: Tales from Rollbacks\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-15 --batch-size 32 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_15.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_16.md#c0", "source": "blogs", "text": "---\nauthor: \"ML Eng\"\npublished_date: \"2024-11-09\"\ntitle: \"Dataset Size Limits in the Wild\"\n---\n# Dataset Size Limits in the Wild\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-16 --batch-size 64 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_16.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_17.md#c0", "source": "blogs", "text": "---\nauthor: \"SRE\"\npublished_date: \"2025-04-08\"\ntitle: \"Checkpoints Under Spot Preemption\"\n---\n# Checkpoints Under Spot Preemption\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-17 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_17.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_18.md#c0", "source": "blogs", "text": "---\nauthor: \"Community\"\npublished_date: \"2024-12-23\"\ntitle: \"Billing Surprises and Idle GPUs\"\n---\n# Billing Surprises and Idle GPUs\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-18 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler step\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_18.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_19.md#c0", "source": "blogs", "text": "---\nauthor: \"Community\"\npublished_date: \"2024-12-09\"\ntitle: \"Drift Monitoring We Wish We Had\"\n---\n# Drift Monitoring We Wish We Had\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-19 --batch-size 64 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_19.md", "author": "", "published_date": "", "content_type": "prose"}}
{"id": "data/blogs/post_20.md#c0", "source": "blogs", "text": "---\nauthor: \"Ops\"\npublished_date: \"2025-04-29\"\ntitle: \"Tuning Service Under Constraints\"\n---\n# Tuning Service Under Constraints\n## Context\nThis post reflects field experience rather than policy. Numbers are indicative and may not match every workload. We call out divergences from v2.1 docs where applicable.\n\n## Findings\n- Observation on workload shape and throughput/latency trade-offs.\n- Cases where the documented defaults underperform (and why).\n- Surprising behavior on legacy tenants and migration caveats.\n\n## Examples\n\n```bash\nastraml submit --project demo --model roberta-base --gpus 1 \\      --dataset s3://bucket/blog-ds-20 --batch-size 48 \\      --epochs 5 --lr 3e-5 --lr-scheduler cosine\n```\n\n\n## Recommendations\nStart with documented defaults, then profile. Increase batch_size only when memory headroom is measured. Prefer cosine for long runs; step may fit short, sharp schedules. Consider 60-day artifact retention in regulated environments, despite 30-day default.\n\nTokenization overhead can dominate at small batch sizes; pipeline parallelism helps minimally. Autoscaling sensitivity to queue depth interacts with retry storms; tune cooldowns accordingly. Metrics at 10s granularity improve RCA but can raise storage and I/O costs by double digits.", "meta": {"post_title": "post_20.md", "author": "", "published_date": "", "content_type": "prose"}}
